{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# exercise 5.2.3\n",
    "\n",
    "from pylab import *\n",
    "from sklearn import cross_validation, tree\n",
    "from toolbox_02450 import feature_selector_lr, bmplot\n",
    "import sklearn.linear_model as lm\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "#print plots inline\n",
    "%matplotlib inline\n",
    "\n",
    "#Define names\n",
    "names = ['word_freq_make', 'word_freq_address', 'word_freq_all',\n",
    "         'word_freq_3d', 'word_freq_our', 'word_freq_over',\n",
    "         'word_freq_remove', 'word_freq_internet', 'word_freq_order',\n",
    "         'word_freq_mail', 'word_freq_receive', 'word_freq_will',\n",
    "         'word_freq_people', 'word_freq_report', 'word_freq_addresses',\n",
    "         'word_freq_free', 'word_freq_business', 'word_freq_email',\n",
    "         'word_freq_you', 'word_freq_credit', 'word_freq_your',\n",
    "         'word_freq_font', 'word_freq_000', 'word_freq_money',\n",
    "         'word_freq_hp', 'word_freq_hpl', 'word_freq_george',\n",
    "         'word_freq_650', 'word_freq_lab', 'word_freq_labs',\n",
    "         'word_freq_telnet', 'word_freq_857', 'word_freq_data',\n",
    "         'word_freq_415', 'word_freq_85', 'word_freq_technology',\n",
    "         'word_freq_1999', 'word_freq_parts', 'word_freq_pm',\n",
    "         'word_freq_direct', 'word_freq_cs', 'word_freq_meeting',\n",
    "         'word_freq_original', 'word_freq_project', 'word_freq_re',\n",
    "         'word_freq_edu', 'word_freq_table', 'word_freq_conference',\n",
    "         'char_freq_;', 'char_freq_(', 'char_freq_[', 'char_freq_!',\n",
    "         'char_freq_$', 'char_freq_#']\n",
    "tst=['capital_run_length_average', 'capital_run_length_longest',\n",
    "     'capital_run_length_total']\n",
    "\n",
    "#clean up names\n",
    "names=[s.replace('word_freq_','').replace('char_freq_','') for s in names]\n",
    "\n",
    "#Load data\n",
    "freq = pd.read_csv(\"../data/spambase.data\",names=names,usecols=range(54))\n",
    "Y = pd.read_csv(\"../data/spambase.data\",usecols=[57],names=['spam'])\n",
    "\n",
    "freq.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get data and standardize\n",
    "df = pd.read_csv(\"../data/spambase.data\",names=names+tst,usecols=range(57))\n",
    "Xd = (df - df.mean()) / (df.max() - df.min())\n",
    "Xd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df.as_matrix()\n",
    "y = Y.spam.values\n",
    "X = np.asmatrix(X)\n",
    "y = np.asmatrix(y).T\n",
    "#attributeNames = [name[0] for name in mat_data['attributeNames'][0]]\n",
    "#classNames = [name[0][0] for name in mat_data['classNames']]\n",
    "N, M = X.shape\n",
    "#C = len(classNames)\n",
    "\n",
    "# Tree complexity parameter - constraint on maximum depth\n",
    "tc = np.arange(2, 54, 1)\n",
    "\n",
    "# K-fold crossvalidation\n",
    "K = 10\n",
    "CV = cross_validation.KFold(N,K,shuffle=True)\n",
    "\n",
    "# Initialize variable\n",
    "Error_train = np.empty((len(tc),K))\n",
    "Error_test = np.empty((len(tc),K))\n",
    "\n",
    "k=0\n",
    "for train_index, test_index in CV:\n",
    "    print('Computing CV fold: {0}/{1}..'.format(k+1,K))\n",
    "\n",
    "    # extract training and test set for current CV fold\n",
    "    X_train, y_train = X[train_index,:].A, y[train_index,:].A\n",
    "    X_test, y_test = X[test_index,:].A, y[test_index,:].A\n",
    "\n",
    "    for i, t in enumerate(tc):\n",
    "        # Fit decision tree classifier, Gini split criterion, different pruning levels\n",
    "        dtc = tree.DecisionTreeClassifier(criterion='gini', max_depth=t)\n",
    "        dtc = dtc.fit(X_train,y_train.ravel())\n",
    "        y_est_test = dtc.predict(X_test)\n",
    "        y_est_train = dtc.predict(X_train)\n",
    "        # Evaluate misclassification rate over train/test data (in this CV fold)\n",
    "        misclass_rate_test = sum(np.abs(np.mat(y_est_test).T - y_test)) / float(len(y_est_test))\n",
    "        misclass_rate_train = sum(np.abs(np.mat(y_est_train).T - y_train)) / float(len(y_est_train))\n",
    "        Error_test[i,k], Error_train[i,k] = misclass_rate_test, misclass_rate_train\n",
    "    k+=1\n",
    "\n",
    "\n",
    "f = figure(); f.hold(True)\n",
    "boxplot(Error_test.T)\n",
    "xlabel('Model complexity (max tree depth)')\n",
    "ylabel('Test error across CV folds, K={0})'.format(K))\n",
    "\n",
    "f = figure(); f.hold(True)\n",
    "plot(tc, Error_train.mean(1))\n",
    "plot(tc, Error_test.mean(1))\n",
    "xlabel('Model complexity (max tree depth)')\n",
    "ylabel('Error (misclassification rate, CV K={0})'.format(K))\n",
    "legend(['Error_train','Error_test'])\n",
    "\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df.as_matrix()\n",
    "y = Y.spam.values\n",
    "X = np.asmatrix(X)\n",
    "y = np.asmatrix(y).T\n",
    "#attributeNames = [name[0] for name in names]\n",
    "#classNames = [name[0][0] for name in mat_data['classNames']]\n",
    "N, M = X.shape\n",
    "# Add offset attribute\n",
    "X = np.concatenate((np.ones((X.shape[0],1)),X),1)\n",
    "attributeNames = [u'Offset']+names\n",
    "M = M+1\n",
    "\n",
    "## Crossvalidation\n",
    "# Create crossvalidation partition for evaluation\n",
    "K = 5\n",
    "CV = cross_validation.KFold(N,K,shuffle=True)\n",
    "\n",
    "# Initialize variables\n",
    "Features = np.zeros((M,K))\n",
    "Error_train = np.empty((K,1))\n",
    "Error_test = np.empty((K,1))\n",
    "Error_train_fs = np.empty((K,1))\n",
    "Error_test_fs = np.empty((K,1))\n",
    "Error_train_nofeatures = np.empty((K,1))\n",
    "Error_test_nofeatures = np.empty((K,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k=0\n",
    "for train_index, test_index in CV:\n",
    "\n",
    "    # extract training and test set for current CV fold\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    \n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "    internal_cross_validation = 10\n",
    "\n",
    "    # Compute squared error without using the input data at all\n",
    "    Error_train_nofeatures[k] = np.square(y_train-y_train.mean()).sum()/y_train.shape[0]\n",
    "    Error_test_nofeatures[k] = np.square(y_test-y_test.mean()).sum()/y_test.shape[0]\n",
    "\n",
    "    # Compute squared error with all features selected (no feature selection)\n",
    "    m = lm.LinearRegression().fit(X_train, y_train)\n",
    "    Error_train[k] = np.square(y_train-m.predict(X_train)).sum()/y_train.shape[0]\n",
    "    Error_test[k] = np.square(y_test-m.predict(X_test)).sum()/y_test.shape[0]\n",
    "\n",
    "    # Compute squared error with feature subset selection\n",
    "    selected_features, features_record, loss_record = feature_selector_lr(X_train, \n",
    "                                                                          y_train, internal_cross_validation)\n",
    "   \n",
    "    print(selected_features)\n",
    "    Features[selected_features,k]=1\n",
    "    # .. alternatively you could use module sklearn.feature_selection\n",
    "    print(y_train.shape)\n",
    "    print(X_train[:,selected_features])\n",
    "    m = lm.LinearRegression().fit(X_train[:,selected_features], y_train)\n",
    "    Error_train_fs[k] = np.square(y_train-m.predict(X_train[:,selected_features])).sum()/y_train.shape[0]\n",
    "    Error_test_fs[k] = np.square(y_test-m.predict(X_test[:,selected_features])).sum()/y_test.shape[0]\n",
    "\n",
    "    figure(k)\n",
    "    subplot(1,2,1)\n",
    "    plot(range(1,len(loss_record)), loss_record[1:])\n",
    "    xlabel('Iteration')\n",
    "    ylabel('Squared error (crossvalidation)')\n",
    "\n",
    "    subplot(1,3,3)\n",
    "    bmplot(attributeNames, range(1,features_record.shape[1]), -features_record[:,1:])\n",
    "    clim(-1.5,0)\n",
    "    xlabel('Iteration')\n",
    "\n",
    "   # print('Cross validation fold {0}/{1}'.format(k+1,K))\n",
    "   # print('Train indices: {0}'.format(train_index))\n",
    "   # print('Test indices: {0}'.format(test_index))\n",
    "   # print('Features no: {0}\\n'.format(selected_features.size))\n",
    "\n",
    "    k+=1\n",
    "\n",
    "\n",
    "# Display results\n",
    "print('\\n')\n",
    "print('Linear regression without feature selection:\\n')\n",
    "print('- Training error: {0}'.format(Error_train.mean()))\n",
    "print('- Test error:     {0}'.format(Error_test.mean()))\n",
    "print('- R^2 train:     {0}'.format((Error_train_nofeatures.sum()-Error_train.sum())/Error_train_nofeatures.sum()))\n",
    "print('- R^2 test:     {0}'.format((Error_test_nofeatures.sum()-Error_test.sum())/Error_test_nofeatures.sum()))\n",
    "print('Linear regression with feature selection:\\n')\n",
    "print('- Training error: {0}'.format(Error_train_fs.mean()))\n",
    "print('- Test error:     {0}'.format(Error_test_fs.mean()))\n",
    "print('- R^2 train:     {0}'.format((Error_train_nofeatures.sum()-Error_train_fs.sum())/Error_train_nofeatures.sum()))\n",
    "print('- R^2 test:     {0}'.format((Error_test_nofeatures.sum()-Error_test_fs.sum())/Error_test_nofeatures.sum()))\n",
    "\n",
    "figure(k)\n",
    "subplot(1,3,2)\n",
    "bmplot(attributeNames, range(1,Features.shape[1]+1), -Features)\n",
    "clim(-1.5,0)\n",
    "xlabel('Crossvalidation fold')\n",
    "ylabel('Attribute')\n",
    "\n",
    "\n",
    "# Inspect selected feature coefficients effect on the entire dataset and\n",
    "# plot the fitted model residual error as function of each attribute to\n",
    "# inspect for systematic structure in the residual\n",
    "f=2 # cross-validation fold to inspect\n",
    "ff=Features[:,f-1].nonzero()[0]\n",
    "m = lm.LinearRegression().fit(X[:,ff], y)\n",
    "\n",
    "y_est= m.predict(X[:,ff])\n",
    "residual=y-y_est\n",
    "\n",
    "figure(k+1)\n",
    "title('Residual error vs. Attributes for features selected in cross-validation fold {0}'.format(f))\n",
    "for i in range(0,len(ff)):\n",
    "   subplot(2,ceil(len(ff)/2.0),i+1)\n",
    "   plot(X[:,ff[i]].A,residual.A,'.')\n",
    "   xlabel(attributeNames[ff[i]])\n",
    "   ylabel('residual error')\n",
    "\n",
    "\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N, M = X.shape\n",
    "#C = len(classNames)\n",
    "\n",
    "## Crossvalidation\n",
    "# Create crossvalidation partition for evaluation\n",
    "K = 10\n",
    "CV = cross_validation.KFold(N,K,shuffle=True)\n",
    "\n",
    "# Initialize variables\n",
    "Error_logreg = np.empty((K,1))\n",
    "Error_dectree = np.empty((K,1))\n",
    "n_tested=0\n",
    "\n",
    "k=0\n",
    "for train_index, test_index in CV:\n",
    "    #print(test_index)\n",
    "    # extract training and test set for current CV fold\n",
    "    X_train = X[train_index,:]\n",
    "    y_train = y[train_index,:]\n",
    "    X_test = X[test_index,:]\n",
    "    y_test = y[test_index,:]\n",
    "\n",
    "    # Fit and evaluate Logistic Regression classifier\n",
    "    model = lm.logistic.LogisticRegression(C=N)\n",
    "    model = model.fit(X_train, y_train.A.ravel())\n",
    "    y_logreg = np.mat(model.predict(X_test)).T\n",
    "    Error_logreg[k] = 100*(y_logreg!=y_test).sum().astype(float)/len(y_test)\n",
    "    \n",
    "    # Fit and evaluate Decision Tree classifier\n",
    "    model2 = tree.DecisionTreeClassifier()\n",
    "    model2 = model2.fit(X_train, y_train.A.ravel())\n",
    "    y_dectree = np.mat(model2.predict(X_test)).T\n",
    "    Error_dectree[k] = 100*(y_dectree!=y_test).sum().astype(float)/len(y_test)\n",
    "\n",
    "    k+=1\n",
    "\n",
    "# Use T-test to check if classifiers are significantly different\n",
    "[tstatistic, pvalue] = stats.ttest_ind(Error_logreg,Error_dectree)\n",
    "if pvalue<=0.05:\n",
    "    print('Classifiers are significantly different. (p={0})'.format(pvalue[0]))\n",
    "else:\n",
    "    print('Classifiers are not significantly different (p={0})'.format(pvalue[0]))        \n",
    "    \n",
    "# Boxplot to compare classifier error distributions\n",
    "figure()\n",
    "boxplot(np.bmat('Error_logreg, Error_dectree'))\n",
    "xlabel('Logistic Regression   vs.   Decision Tree')\n",
    "ylabel('Cross-validation error [%]')\n",
    "\n",
    "show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
